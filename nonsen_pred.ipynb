{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "18e907c5-d937-440c-a085-4bd9ffa9d46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Fold 0\n",
      "TRAIN: 11786 TEST: 2947\n",
      "Epoch 0, the train loss is 0.6924, the test loss is 0.6750\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'list' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-fb39f418edc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch %d, the train loss is %.4f, the test loss is %.4f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0meval_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m               \u001b[0mpatience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m               \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'list' and 'float'"
     ]
    }
   ],
   "source": [
    "# load data \n",
    "import argparse\n",
    "import os \n",
    "import json\n",
    "import glob \n",
    "import copy \n",
    "import pickle\n",
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "mse_loss = nn.MSELoss()\n",
    "import utils\n",
    "from utils import AverageMeterSet\n",
    "import prepare_data\n",
    "import models\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn.metrics as metrics\n",
    "kf = KFold(n_splits=5, random_state=None, shuffle=False)\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "date = today.strftime(\"%m%d\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib \n",
    "import seaborn as sns \n",
    "matplotlib.rcParams[\"figure.dpi\"] = 300\n",
    "plt.style.use('bmh')\n",
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "legend_properties = {'weight':'bold', 'size': 14}\n",
    "legend_properties_s = {'weight':'bold', 'size': 10}\n",
    "dir_data = {'satori': '/nobackup/users/weiliao', 'colab':'/content/drive/MyDrive/ColabNotebooks/MIMIC/Extract/MEEP/Extracted_sep_2022/0910'}\n",
    "# load data\n",
    "meep_mimic = np.load(dir_data['satori'] + '/MIMIC_compile_0911_2022.npy', \\\n",
    "                allow_pickle=True).item()\n",
    "train_vital = meep_mimic ['train_head']\n",
    "dev_vital = meep_mimic ['dev_head']\n",
    "test_vital = meep_mimic ['test_head']\n",
    "mimic_static = np.load(dir_data['satori'] + '/MIMIC_static_0922_2022.npy', \\\n",
    "                        allow_pickle=True).item()\n",
    "mimic_target = np.load(dir_data['satori'] + '/MIMIC_target_0922_2022.npy', \\\n",
    "                        allow_pickle=True).item()\n",
    " \n",
    "class Args:\n",
    "    def __init__(self, d=None):\n",
    "        if d is not None:\n",
    "            for key, value in d.items():\n",
    "                setattr(self, key, value)\n",
    "\n",
    "base_dir = '/home/weiliao/FR-TSVAE/checkpoints/'\n",
    "wn = '0512_lr1e-4beta.001_res_regrtheta_5_mlp_regr_nonsens_sens0_mask'\n",
    "p = base_dir + wn + '/' + 'stage1_sofa_fold_0_epoch37.pt'\n",
    "mlp_params = [19, 200, 2]\n",
    "\n",
    "\n",
    "with open(base_dir+wn+'/params.json') as f: \n",
    "    params = json.load(f)\n",
    "params['platform'] = 'satori'\n",
    "params['device_id'] = 0 \n",
    "args = Args(params)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_head, train_static, train_sofa, train_id =  utils.crop_data_target('mimic', train_vital, mimic_target, mimic_static, 'train', args.sens_ind)\n",
    "dev_head, dev_static, dev_sofa, dev_id =  utils.crop_data_target('mimic', dev_vital , mimic_target, mimic_static, 'dev',  args.sens_ind)\n",
    "test_head, test_static, test_sofa, test_id =  utils.crop_data_target('mimic', test_vital, mimic_target, mimic_static, 'test',  args.sens_ind)\n",
    "\n",
    "if args.use_sepsis3 == True:\n",
    "    train_head, train_static, train_sofa, train_id = utils.filter_sepsis('mimic', train_head, train_static, train_sofa, train_id, args.platform)\n",
    "    dev_head, dev_static, dev_sofa, dev_id = utils.filter_sepsis('mimic', dev_head, dev_static, dev_sofa, dev_id, args.platform)\n",
    "    test_head, test_static, test_sofa, test_id = utils.filter_sepsis('mimic', test_head, test_static, test_sofa, test_id, args.platform)\n",
    "\n",
    "# build model\n",
    "model = models.Ffvae(args)\n",
    "MLP_model = models.MLP(mlp_params, 20).to(device)\n",
    "torch.save(MLP_model.state_dict(), '/home/weiliao/FR-TSVAE/start_weights.pt')\n",
    "optimizer = torch.optim.Adam(MLP_model.parameters(), lr=0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 10-fold cross validation\n",
    "trainval_head = train_head + dev_head\n",
    "trainval_static = train_static + dev_static\n",
    "trainval_stail = train_sofa + dev_sofa\n",
    "trainval_ids = train_id + dev_id\n",
    "\n",
    "# prepare data\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "for c_fold, (train_index, test_index) in enumerate(kf.split(trainval_head)):\n",
    "    best_loss = 1e4\n",
    "    patience = 0\n",
    "    if c_fold >= 1:\n",
    "        model.load_state_dict(torch.load('/home/weiliao/FR-TSVAE/start_weights.pt'))\n",
    "    print('Starting Fold %d' % c_fold)\n",
    "    print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "    train_head, val_head = utils.slice_data(trainval_head, train_index), utils.slice_data(trainval_head, test_index)\n",
    "    train_static, val_static = utils.slice_data(trainval_static, train_index), utils.slice_data(trainval_static, test_index)\n",
    "    train_stail, val_stail = utils.slice_data(trainval_stail, train_index), utils.slice_data(trainval_stail, test_index)\n",
    "    train_id, val_id = utils.slice_data(trainval_ids, train_index), utils.slice_data(trainval_ids, test_index)\n",
    "\n",
    "    train_dataloader, dev_dataloader, test_dataloader = prepare_data.get_data_loader(args, train_head, val_head,\n",
    "                                                                                        test_head, \n",
    "                                                                                        train_stail, val_stail,\n",
    "                                                                                        test_sofa,\n",
    "                                                                                        train_static=train_static,\n",
    "                                                                                        dev_static=val_static,\n",
    "                                                                                        test_static=test_static,\n",
    "                                                                                        train_id=train_id,\n",
    "                                                                                        dev_id=val_id,\n",
    "                                                                                        test_id=test_id)\n",
    "    model.load_state_dict(torch.load(p, map_location='cuda:0'))\n",
    "    \n",
    "    for j in range(args.epochs):\n",
    "        # train \n",
    "        model.eval()\n",
    "        MLP_model.train()\n",
    "        train_loss = []\n",
    "        for vitals, static, target, train_ids, key_mask in train_dataloader:\n",
    "            vitals = vitals.to(device)\n",
    "            static = static.to(device)\n",
    "            target = target.to(device)\n",
    "            key_mask = key_mask.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # (bs, zdim, T)\n",
    "                latent_mu, _ = model.encoder(vitals)\n",
    "\n",
    "            logits, probs = MLP_model(latent_mu[:, model.nonsens_idx, :].transpose(1, 2), mode='discriminator')\n",
    "            logits_m = torch.stack([logits[i][key_mask[i]==0].mean(dim=0) for i in range(len(logits))])\n",
    "            loss = loss_fn(logits_m, static.long())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.detach().cpu().numpy())\n",
    "\n",
    "        # eval \n",
    "        eval_loss = []\n",
    "        MLP_model.eval()\n",
    "        with torch.no_grad():\n",
    "            for vitals, static, target, train_ids, key_mask in dev_dataloader:\n",
    "                vitals = vitals.to(device)\n",
    "                static = static.to(device)\n",
    "                target = target.to(device)\n",
    "                key_mask = key_mask.to(device)\n",
    "\n",
    "                latent_mu, _ = model.encoder(vitals)\n",
    "                logits, probs = MLP_model(latent_mu[:, model.nonsens_idx, :].transpose(1, 2), mode='discriminator')\n",
    "                logits_m = torch.stack([logits[i][key_mask[i]==0].mean(dim=0) for i in range(len(logits))])\n",
    "                loss = loss_fn(logits_m, static.long())\n",
    "                eval_loss.append(loss.detach().cpu().numpy())\n",
    "        print('Epoch %d, the train loss is %.4f, the test loss is %.4f'%(j, np.mean(train_loss), np.mean(eval_loss)))\n",
    "        \n",
    "        if np.mean(eval_loss) < best_loss: \n",
    "              patience = 0 \n",
    "              best_loss = np.mean(eval_loss)\n",
    "              best_model_state = copy.deepcopy(MLP_model.state_dict())\n",
    "        else: \n",
    "              patience += 1 \n",
    "              if patience >= args.patience:\n",
    "                  print(\"Epoch %d :\"%j, \"Early stopped.\")\n",
    "                  torch.save(best_model_state, dir_save[args.platform] + '/checkpoints/' + wn + '/stage3_fold_%d_epoch%d_loss%.5f.pt'%(c_fold, j, eval_loss))\n",
    "                  break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3195a8cb-0c3a-4309-9e27-a2062715b6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "686145fb-e087-45ac-b507-3a2cc928a3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "MLP_model.train()\n",
    "train_loss = []\n",
    "for vitals, static, target, train_ids, key_mask in train_dataloader:\n",
    "    vitals = vitals.to(device)\n",
    "    static = static.to(device)\n",
    "    target = target.to(device)\n",
    "    key_mask = key_mask.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # (bs, zdim, T)\n",
    "        latent_mu, _ = model.encoder(vitals)\n",
    "\n",
    "    logits, probs = MLP_model(latent_mu[:, model.nonsens_idx, :].transpose(1, 2), mode='discriminator')\n",
    "    logits_m = torch.stack([logits[i][key_mask[i]==0].mean(dim=0) for i in range(len(logits))])\n",
    "    loss = loss_fn(logits_m, static.long())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss.append(loss.detach().cpu().numpy())\n",
    "\n",
    "# eval \n",
    "eval_loss = []\n",
    "MLP_model.eval()\n",
    "with torch.no_grad():\n",
    "    for vitals, static, target, train_ids, key_mask in dev_dataloader:\n",
    "        vitals = vitals.to(device)\n",
    "        static = static.to(device)\n",
    "        target = target.to(device)\n",
    "        key_mask = key_mask.to(device)\n",
    "\n",
    "\n",
    "        latent_mu, _ = model.encoder(vitals)\n",
    "        logits, probs = MLP_model(latent_mu[:, model.nonsens_idx, :].transpose(1, 2), mode='discriminator')\n",
    "        logits_m = torch.stack([logits[i][key_mask[i]==0].mean(dim=0) for i in range(len(logits))])\n",
    "        loss = loss_fn(logits_m, static.long())\n",
    "        eval_loss.append(loss.detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4291ba00-8547-4468-b445-408d3a79f957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 174, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b906c65e-8215-4625-8436-ccddee9644b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6fdc254b-5898-4e7c-8a7e-017a8ad93dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0049, 0.4079], device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[1][key_mask[1]==0].mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5454057-35ea-4d88-9731-be4df891b0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previous model setting to eval \n",
    "\n",
    "\n",
    "print(p)\n",
    "#  test on test loader \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8c636a8-8d04-44ed-ae03-53b33a6cfeaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "967e4c28-cc08-456c-ba55-5aeeadc6476a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bba73fd-efc4-4a24-956c-d8b5df021790",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4c69a4a3169a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mMLP_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mvitals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_mask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m                 \u001b[0mvitals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvitals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mstatic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstatic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nobackup/users/weiliao/anaconda3/envs/project/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nobackup/users/weiliao/anaconda3/envs/project/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/FR-TSVAE/prepare_data.py\u001b[0m in \u001b[0;36mcol_fn\u001b[0;34m(batchdata)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;31m# [(200, 48) ---> (200, 100)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     padded_td = [np.pad(batchdata[i][0], pad_width=((0, 0), (0, max_len-batchdata[i][0].shape[-1])), \\\n\u001b[0;32m--> 311\u001b[0;31m                 mode='constant', constant_values=-3) for i in range(len_data)]\n\u001b[0m\u001b[1;32m    312\u001b[0m     \u001b[0;31m# [(48, 1) ---> (100, 1)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     padded_label = [np.pad(batchdata[i][2], pad_width=((0, max_len-batchdata[i][0].shape[-1]), (0, 0)), \\\n",
      "\u001b[0;32m~/FR-TSVAE/prepare_data.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;31m# [(200, 48) ---> (200, 100)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     padded_td = [np.pad(batchdata[i][0], pad_width=((0, 0), (0, max_len-batchdata[i][0].shape[-1])), \\\n\u001b[0;32m--> 311\u001b[0;31m                 mode='constant', constant_values=-3) for i in range(len_data)]\n\u001b[0m\u001b[1;32m    312\u001b[0m     \u001b[0;31m# [(48, 1) ---> (100, 1)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     padded_label = [np.pad(batchdata[i][2], pad_width=((0, max_len-batchdata[i][0].shape[-1]), (0, 0)), \\\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpad\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/nobackup/users/weiliao/anaconda3/envs/project/lib/python3.7/site-packages/numpy/lib/arraypad.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_pair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             \u001b[0mroi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_view_roi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_area_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0m_set_pad_area\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"empty\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nobackup/users/weiliao/anaconda3/envs/project/lib/python3.7/site-packages/numpy/lib/arraypad.py\u001b[0m in \u001b[0;36m_set_pad_area\u001b[0;34m(padded, axis, width_pair, value_pair)\u001b[0m\n\u001b[1;32m    149\u001b[0m     right_slice = _slice_at_axis(\n\u001b[1;32m    150\u001b[0m         slice(padded.shape[axis] - width_pair[1], None), axis)\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mpadded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mright_slice\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for j in range(args.epochs):\n",
    "            model.eval()\n",
    "            MLP_model.train()\n",
    "\n",
    "            for vitals, static, target, train_ids, key_mask in train_dataloader:\n",
    "                vitals = vitals.to(device)\n",
    "                static = static.to(device)\n",
    "                target = target.to(device)\n",
    "                key_mask = key_mask.to(device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    # (bs, zdim, T)\n",
    "                    latent_mu, _ = model.encoder(vitals)\n",
    "\n",
    "                logits, probs = MLP_model(latent_mu[:, model.nonsens_idx, :].transpose(1, 2), mode='discriminator')\n",
    "                logits_m = logits.mean(dim=1)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4df14d73-c659-4e73-9cc0-6dc75e851f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e05ffa0-c996-4624-a82d-afb5b3c4f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "            \n",
    "            # print and record loss \n",
    "            train_loss.loc[len(train_loss)] = average_meters.averages().values()\n",
    "            print(\"EPOCH: \", j, \"TRAIN AVGs: \", average_meters.averages())\n",
    "\n",
    "            model.eval()\n",
    "            average_meters = AverageMeterSet()\n",
    "            with torch.no_grad():\n",
    "                for vitals, static, target, train_ids, key_mask in dev_dataloader:\n",
    "                    vitals = vitals.to(device)\n",
    "                    static = static.to(device)\n",
    "                    target = target.to(device)\n",
    "                    key_mask = key_mask.to(device)\n",
    "\n",
    "                    _, cost_dict = model(vitals, key_mask, target, static, \"test\")\n",
    "\n",
    "                    stats = dict((n, c.item()) for (n, c) in cost_dict.items())\n",
    "                    average_meters.update_dict(stats)\n",
    "                \n",
    "            # print and record loss \n",
    "            dev_loss.loc[len(dev_loss)] = average_meters.averages().values()\n",
    "            print(\"EPOCH: \", j, \"VAL AVGs: \", average_meters.averages())\n",
    "\n",
    "            if average_meters.averages()['ffvae_cost/avg'] < best_loss:\n",
    "                patience = 0 \n",
    "                best_loss = average_meters.averages()['ffvae_cost/avg']\n",
    "                best_model_state = copy.deepcopy(model.state_dict())\n",
    "            else:\n",
    "                patience += 1 \n",
    "                if patience >= args.patience:\n",
    "                    print(\"Epoch %d :\"%j, \"Early stopped.\")\n",
    "                    # torch.save(best_model_state, '/home/weiliao/FR-TSVAE/checkpoints/' + workname + '/stage1_epoch%d.pt'%j)\n",
    "                    break \n",
    "            if average_meters.averages()['clf_term/avg'] < best_clf_loss: \n",
    "                best_clf_loss = average_meters.averages()['clf_term/avg']\n",
    "                best_clf_model = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "            if average_meters.averages()['sofa_term/avg'] < best_sofa_loss: \n",
    "                best_sofa_loss = average_meters.averages()['sofa_term/avg']\n",
    "                best_sofa_model = copy.deepcopy(model.state_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
