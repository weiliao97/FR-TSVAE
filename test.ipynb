{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and compare trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os \n",
    "import json\n",
    "import glob \n",
    "import copy \n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "mse_loss = nn.MSELoss()\n",
    "import utils\n",
    "from utils import AverageMeterSet\n",
    "import prepare_data\n",
    "import models\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn.metrics as metrics\n",
    "kf = KFold(n_splits=5, random_state=None, shuffle=False)\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "date = today.strftime(\"%m%d\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib \n",
    "import seaborn as sns \n",
    "matplotlib.rcParams[\"figure.dpi\"] = 300\n",
    "plt.style.use('bmh')\n",
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "legend_properties = {'weight':'bold', 'size': 14}\n",
    "legend_properties_s = {'weight':'bold', 'size': 10}\n",
    "dir_data = {'satori': '/nobackup/users/weiliao', 'colab':'/content/drive/MyDrive/ColabNotebooks/MIMIC/Extract/MEEP/Extracted_sep_2022/0910'}\n",
    "# load data\n",
    "meep_mimic = np.load(dir_data['colab'] + '/MIMIC_compile_0911_2022.npy', \\\n",
    "                allow_pickle=True).item()\n",
    "train_vital = meep_mimic ['train_head']\n",
    "dev_vital = meep_mimic ['dev_head']\n",
    "test_vital = meep_mimic ['test_head']\n",
    "mimic_static = np.load(dir_data['colab'] + '/MIMIC_static_0922_2022.npy', \\\n",
    "                        allow_pickle=True).item()\n",
    "mimic_target = np.load(dir_data['colab'] + '/MIMIC_target_0922_2022.npy', \\\n",
    "                        allow_pickle=True).item()\n",
    " \n",
    "class Args:\n",
    "    def __init__(self, d=None):\n",
    "        if d is not None:\n",
    "            for key, value in d.items():\n",
    "                setattr(self, key, value)\n",
    "\n",
    "base_dir = '/content/drive/My Drive/ColabNotebooks/MIMIC/TCN/VAE/checkpoints/'\n",
    "\n",
    "workname_list = ['0505_lr1e-4beta.001_res_regrtheta_5_mlp_regr_nonsens',\n",
    "                 '0506_lr1e-4beta.001_res_regrtheta_5_mlp_regr_nonsens_sens_1',\n",
    "                 '0507_lr1e-4beta.001_res_regrtheta_5_mlp_regr_nonsens_21',\n",
    "                 '0511_lr1e-4beta.001_res_regrtheta_5_mlp_regr_nonsens_sens0_bs64',\n",
    "                 '0511_lr1e-4beta.001_res_regrtheta_5_mlp_regr_nonsens_sens1_bs64',\n",
    "                 '0511_lr1e-4beta.001_res_regrtheta_5_mlp_regr_nonsens_sens21_bs64'\n",
    "                 ]\n",
    "\n",
    "for wn in workname_list:\n",
    "\n",
    "    all_path = glob.glob(base_dir + wn + '/*.pt')\n",
    "    all_path = [p for p in all_path if \"stage2\" not in p]\n",
    "    with open(base_dir+wn+'/params.json') as f: \n",
    "        params = json.load(f)\n",
    "    params['platform'] = 'colab'\n",
    "    args = Args(params)\n",
    "    device = torch.device(\"cuda:%d\"%args.device_id if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    train_head, train_static, train_sofa, train_id =  utils.crop_data_target('mimic', train_vital, mimic_target, mimic_static, 'train', args.sens_ind)\n",
    "    dev_head, dev_static, dev_sofa, dev_id =  utils.crop_data_target('mimic', dev_vital , mimic_target, mimic_static, 'dev',  args.sens_ind)\n",
    "    test_head, test_static, test_sofa, test_id =  utils.crop_data_target('mimic', test_vital, mimic_target, mimic_static, 'test',  args.sens_ind)\n",
    "\n",
    "    if args.use_sepsis3 == True:\n",
    "        train_head, train_static, train_sofa, train_id = utils.filter_sepsis('mimic', train_head, train_static, train_sofa, train_id, args.platform)\n",
    "        dev_head, dev_static, dev_sofa, dev_id = utils.filter_sepsis('mimic', dev_head, dev_static, dev_sofa, dev_id, args.platform)\n",
    "        test_head, test_static, test_sofa, test_id = utils.filter_sepsis('mimic', test_head, test_static, test_sofa, test_id, args.platform)\n",
    "\n",
    "    # build model\n",
    "    model = models.Ffvae(args)\n",
    "    # torch.save(model.state_dict(), '/home/weiliao/FR-TSVAE/start_weights.pt')\n",
    "\n",
    "    # 10-fold cross validation\n",
    "    trainval_head = train_head + dev_head\n",
    "    trainval_static = train_static + dev_static\n",
    "    trainval_stail = train_sofa + dev_sofa\n",
    "    trainval_ids = train_id + dev_id\n",
    "\n",
    "    # prepare data\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    for c_fold, (train_index, test_index) in enumerate(kf.split(trainval_head)):\n",
    "        # best_loss = 1e4\n",
    "        # patience = 0\n",
    "        # if c_fold >= 1:\n",
    "        #     model.load_state_dict(torch.load('/home/weiliao/FR-TSVAE/start_weights.pt'))\n",
    "        print('Starting Fold %d' % c_fold)\n",
    "        print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "        train_head, val_head = utils.slice_data(trainval_head, train_index), utils.slice_data(trainval_head, test_index)\n",
    "        train_static, val_static = utils.slice_data(trainval_static, train_index), utils.slice_data(trainval_static, test_index)\n",
    "        train_stail, val_stail = utils.slice_data(trainval_stail, train_index), utils.slice_data(trainval_stail, test_index)\n",
    "        train_id, val_id = utils.slice_data(trainval_ids, train_index), utils.slice_data(trainval_ids, test_index)\n",
    "\n",
    "        train_dataloader, dev_dataloader, test_dataloader = prepare_data.get_data_loader(args, train_head, val_head,\n",
    "                                                                                            test_head, \n",
    "                                                                                            train_stail, val_stail,\n",
    "                                                                                            test_sofa,\n",
    "                                                                                            train_static=train_static,\n",
    "                                                                                            dev_static=val_static,\n",
    "                                                                                            test_static=test_static,\n",
    "                                                                                            train_id=train_id,\n",
    "                                                                                            dev_id=val_id,\n",
    "                                                                                            test_id=test_id)\n",
    "    # prepare id_20 \n",
    "    stay_ids = [30534026, 32238007, 30134473, 37221316, 36824639, 30397073, 39298593, 34590507, 36437173, \n",
    "                38656645, 36688715, 37461900, 31176570, 38392389, 37603454, 37741158, 37605174, 33792670, 36939508, 37602211]\n",
    "    idmap = {}\n",
    "    for i, ids in enumerate(test_id): \n",
    "        idmap[ids] = i \n",
    "    # convert id to index \n",
    "    id_20 = []\n",
    "    for ids in stay_ids: \n",
    "        id_20.append(idmap[ids])\n",
    "    # deal with CM and AUC plots, 3d \n",
    "    for p in all_path: \n",
    "        # creat a subfolder to save the test results\n",
    "        curr_dir = base_dir + wn + '/'+ p.split('/')[-1].split('.')[0]\n",
    "        if not os.path.exists(curr_dir):\n",
    "            os.makedirs(curr_dir)\n",
    "        model.load_state_dict(torch.load(p))\n",
    "        print(p)\n",
    "        #  test on test loader \n",
    "        model.eval()\n",
    "        logits = []\n",
    "        stt = []\n",
    "        sofa_loss = []\n",
    "        with torch.no_grad():\n",
    "            for vitals, static, target, train_ids, key_mask in test_dataloader:\n",
    "                # (bs, feature_dim, T)\n",
    "                vitals = vitals.to(device)\n",
    "                # (bs)\n",
    "                static = static.to(device)\n",
    "                # (bs, T, 1)\n",
    "                target = target.to(device)\n",
    "                # (bs, T)\n",
    "                key_mask = key_mask.to(device)\n",
    "\n",
    "                # _mu shape [bs, zdim, T]\n",
    "                _mu, _logvar = model.encoder(vitals)\n",
    "                # b_logits [bs, 1]\n",
    "                b_logits = _mu[:, model.sens_idx]\n",
    "                mu = _mu[:, model.nonsens_idx, :]\n",
    "                # (bs, T, 1)\n",
    "                sofa_p = model.regr(mu.transpose(1, 2), \"classify\")\n",
    "                sofa_loss.extend([mse_loss(sofa_p[i][key_mask[i]==0], target[i][key_mask[i]==0]) for i in range(len(sofa_p))])\n",
    "                # for static info prediction \n",
    "                logits.extend(torch.stack([b_logits[i].squeeze(0).mean() for i in range(len(b_logits))]))\n",
    "                stt.extend(static)\n",
    "        # save the sofa test result to file \n",
    "        test_loss = torch.mean(torch.stack(sofa_loss)).cpu().numpy()\n",
    "        with open(curr_dir + '/sofa_test.json', 'w') as f:\n",
    "            json.dump(str(test_loss), f)\n",
    "        print(test_loss)\n",
    "        \n",
    "        # display AUC \n",
    "        logits = torch.stack(logits)\n",
    "        stt = torch.stack(stt) \n",
    "        metrics.RocCurveDisplay.from_predictions(stt.cpu(),  nn.Sigmoid()(logits).cpu())  \n",
    "        fig = plt.gcf()\n",
    "        plt.show()\n",
    "        fig.savefig(curr_dir + '/auc.eps', format='eps', bbox_inches = 'tight', pad_inches = 0.1, dpi=1200)\n",
    "\n",
    "        # calculate optimal threshold\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(stt.cpu(),  nn.Sigmoid()(logits).cpu())\n",
    "        gmeans = np.sqrt(tpr * (1-fpr))\n",
    "        opt_th = thresholds[np.argmax(gmeans)]\n",
    "\n",
    "        for th in [0.5, opt_th]:\n",
    "\n",
    "            pred =  (nn.Sigmoid()(logits).cpu() > th).float()\n",
    "            cm = metrics.confusion_matrix(stt.cpu(), pred)\n",
    "            cf_matrix = cm/np.repeat(np.expand_dims(np.sum(cm, axis=1), axis=-1), 2, axis=1)\n",
    "            group_counts = ['{0:0.0f}'.format(value) for value in cm.flatten()]\n",
    "            # percentage based on true label \n",
    "            gr = (cm/np.repeat(np.expand_dims(np.sum(cm, axis=1), axis=-1), 2, axis=1)).flatten()\n",
    "            group_percentages = ['{0:.2%}'.format(value) for value in gr]\n",
    "\n",
    "            labels = [f'{v1}\\n{v2}' for v1, v2 in zip(group_percentages, group_counts)]\n",
    "\n",
    "            labels = np.asarray(labels).reshape(2, 2)\n",
    "            \n",
    "            if args.sens_ind == 0:\n",
    "                xlabel = ['Pred-%s'%l for l in ['F', 'M']]\n",
    "                ylabel = ['%s'%l for l in ['F', 'M']]   \n",
    "            elif args.sens_ind == 1: \n",
    "                xlabel = ['Pred-%s'%l for l in ['Y', 'E']]\n",
    "                ylabel = ['%s'%l for l in ['Y', 'E']]   \n",
    "            elif args.sens_ind == 21: \n",
    "                xlabel = ['Pred-%s'%l for l in ['W', 'B']]\n",
    "                ylabel = ['%s'%l for l in ['W', 'B']]   \n",
    "\n",
    "            sns.set(font_scale = 1.5)\n",
    "\n",
    "            hm = sns.heatmap(cf_matrix, annot=labels, fmt='', cmap = 'OrRd', \\\n",
    "            annot_kws={\"fontsize\": 16}, xticklabels=xlabel, yticklabels=ylabel, cbar=False)\n",
    "            # hm.set(title=title)\n",
    "            fig = plt.gcf()\n",
    "            plt.show()  \n",
    "            fig.savefig(curr_dir + '/cm_%f.eps'%th, format='eps', bbox_inches = 'tight', pad_inches = 0.1, dpi=1200)\n",
    "        \n",
    "        for v in ['raw', 'smooth']: \n",
    "            fig, ax = plt.subplots(4, 5, figsize=(25, 12))\n",
    "            axes = ax.flatten()\n",
    "            for i in range(20):\n",
    "                id = test_id[id_20[i]]\n",
    "                sofa = mimic_target['test'][id]\n",
    "                _mu, _logvar = model.encoder(torch.FloatTensor(test_head[id_20[i]]).unsqueeze(0).to(device))\n",
    "                mu = _mu[:, model.nonsens_idx, :]\n",
    "                sofa_p = model.regr(mu.transpose(1, 2), \"classify\").squeeze(0).cpu().detach().numpy()*15\n",
    "                if v == 'smooth': \n",
    "                    sofa_p = [np.round(i) for i in sofa_p]\n",
    "                n = len(sofa)\n",
    "                axes[i].plot(range(len(sofa)), sofa, label='Current SOFA')\n",
    "                axes[i].plot(range(24, n), sofa_p, c=\"tab:green\", label ='Predicted SOFA')\n",
    "                axes[i].set_xlim((0, len(sofa)))\n",
    "                axes[i].tick_params(axis='both', labelsize=8)\n",
    "                if max(sofa) <= 11 and int(max(sofa_p)) <=11:\n",
    "                    axes[i].set_ylim((0, 12))\n",
    "                else: \n",
    "                    axes[i].set_ylim((0, max(max(sofa), int(max(sofa_p)))+1))\n",
    "                if i == 0: \n",
    "                    axes[i].set_ylabel('SOFA score', size=14,  fontweight='bold')\n",
    "                if i == 19:\n",
    "                    axes[i].set_xlabel('ICU_in Hours', size=14,  fontweight='bold')\n",
    "                if i == 4:\n",
    "                    axes[i].legend(loc='upper right',  prop=legend_properties)\n",
    "                # save each small figure \n",
    "                fig_s, ax_s = plt.subplots(1, 1, figsize=(5, 3))\n",
    "                ax_s.plot(range(len(sofa)), sofa, label='Current SOFA')\n",
    "                ax_s.plot(range(24, n), sofa_p, c=\"tab:green\", label ='Predicted SOFA')\n",
    "                ax_s.set_xlim((0, len(sofa)))\n",
    "                ax_s.tick_params(axis='both', labelsize=6)\n",
    "                if max(sofa) <= 11 and int(max(sofa_p)) <=11:\n",
    "                    ax_s.set_ylim((0, 12))\n",
    "                else: \n",
    "                    ax_s.set_ylim((0, max(max(sofa), int(max(sofa_p)))+1))\n",
    "                ax_s.set_ylabel('SOFA score', size=12,  fontweight='bold')\n",
    "                ax_s.set_xlabel('ICU_in Hours', size=12,  fontweight='bold')\n",
    "                ax_s.legend(loc='upper right',  prop=legend_properties_s)\n",
    "                fig_s.savefig(curr_dir + '/indiv_sofa_%s_%d.eps'%(v, i), format='eps', bbox_inches = 'tight', pad_inches = 0.1, dpi=1200)\n",
    "\n",
    "            # save the big figure \n",
    "            fig.savefig(curr_dir + '/sofa_%s.eps'%v, format='eps', bbox_inches = 'tight', pad_inches = 0.1, dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
